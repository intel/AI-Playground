{
  "type": "comfy",
  "name": "HD Image",
  "displayPriority": 400,
  "tags": ["JuggernautXL", "1024x1024"],
  "backend": "comfyui",
  "category": "create-images",
  "description": "Generate high quality images using SDXL",
  "mediaType": "image",
  "toolEnabled": true,
  "toolInstructions": "Generate a detailed, descriptive prompt that includes: subject details, composition, style, lighting, colors, mood, and quality tags. SDXL produces higher quality images than SD1.5, so emphasize photorealistic details and professional quality. Even if the user requests something simple like 'a cat', expand it to a full prompt like 'a beautiful orange tabby cat sitting on a windowsill, soft natural lighting, detailed fur texture, photorealistic, 8k, highly detailed, professional photography, shallow depth of field'.",
  "resolutionConfig": {
    "megapixels": [
      { "label": "0.25", "totalPixels": 262144 },
      { "label": "0.5", "totalPixels": 495616 },
      { "label": "0.8", "totalPixels": 802816 },
      { "label": "1.0", "totalPixels": 1048576 }
    ],
    "aspectRatios": ["21/9", "16/9", "3/2", "4/3", "1/1", "3/4", "2/3", "9/16", "9/21"]
  },
  "requiredCustomNodes": [],
  "requiredPythonPackages": [],
  "requiredModels": [
    {
      "type": "checkpoints",
      "model": "RunDiffusion/Juggernaut-XL-v9/Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors"
    }
  ],
  "variants": [
    {
      "name": "Fast",
      "overrides": {
        "requiredModels": [
          {
            "type": "checkpoints",
            "model": "RunDiffusion/Juggernaut-XL-v9/Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors"
          },
          {
            "type": "lora",
            "model": "latent-consistency/lcm-lora-sdxl/pytorch_lora_weights.safetensors"
          }
        ],
        "settings": [
          {
            "type": "number",
            "label": "Inference Steps",
            "displayed": true,
            "modifiable": true,
            "defaultValue": 4,
            "settingName": "inferenceSteps"
          }
        ],
        "comfyUiApiWorkflow": {
          "3": {
            "inputs": {
              "steps": 4,
              "cfg": 1.5,
              "sampler_name": "lcm",
              "scheduler": "simple",
              "model": ["10", 0]
            },
            "class_type": "KSampler",
            "_meta": {
              "title": "KSampler"
            }
          },
          "10": {
            "inputs": {
              "lora_name": "latent-consistency---lcm-lora-sdxl\\pytorch_lora_weights.safetensors",
              "strength_model": 1,
              "strength_clip": 1,
              "model": ["4", 0],
              "clip": ["4", 1]
            },
            "class_type": "LoraLoader",
            "_meta": {
              "title": "Load LoRA"
            }
          },
          "6": {
            "inputs": {
              "clip": ["10", 1]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {
              "title": "prompt"
            }
          },
          "7": {
            "inputs": {
              "clip": ["10", 1]
            },
            "class_type": "CLIPTextEncode",
            "_meta": {
              "title": "negativePrompt"
            }
          }
        }
      }
    },
    {
      "name": "Quality",
      "overrides": {}
    }
  ],
  "settings": [
    {
      "type": "string",
      "label": "Prompt",
      "displayed": false,
      "modifiable": true,
      "defaultValue": "",
      "settingName": "prompt"
    },
    {
      "type": "number",
      "label": "Seed",
      "displayed": true,
      "modifiable": true,
      "defaultValue": -1,
      "settingName": "seed"
    },
    {
      "type": "number",
      "label": "Inference Steps",
      "displayed": true,
      "modifiable": true,
      "defaultValue": 20,
      "settingName": "inferenceSteps"
    },
    {
      "type": "number",
      "label": "Width",
      "displayed": false,
      "modifiable": false,
      "defaultValue": 1024,
      "settingName": "width"
    },
    {
      "type": "number",
      "label": "Height",
      "displayed": false,
      "modifiable": false,
      "defaultValue": 1024,
      "settingName": "height"
    },
    {
      "type": "string",
      "label": "Resolution",
      "displayed": true,
      "modifiable": true,
      "defaultValue": "1024x1024",
      "settingName": "resolution"
    },
    {
      "type": "number",
      "label": "Batch Size",
      "displayed": true,
      "modifiable": true,
      "defaultValue": 1,
      "settingName": "batchSize"
    },
    {
      "type": "string",
      "label": "Negative Prompt",
      "displayed": true,
      "modifiable": true,
      "defaultValue": "nsfw",
      "settingName": "negativePrompt"
    },
    {
      "type": "boolean",
      "label": "Safety Check",
      "displayed": false,
      "modifiable": false,
      "defaultValue": true,
      "settingName": "safetyCheck"
    }
  ],
  "comfyUiApiWorkflow": {
    "3": {
      "inputs": {
        "seed": 413053266758155,
        "steps": 20,
        "cfg": 7,
        "sampler_name": "dpmpp_2m",
        "scheduler": "normal",
        "denoise": 1,
        "model": ["4", 0],
        "positive": ["6", 0],
        "negative": ["7", 0],
        "latent_image": ["5", 0]
      },
      "class_type": "KSampler",
      "_meta": {
        "title": "KSampler"
      }
    },
    "4": {
      "inputs": {
        "ckpt_name": "RunDiffusion---Juggernaut-XL-v9\\Juggernaut-XL_v9_RunDiffusionPhoto_v2.safetensors"
      },
      "class_type": "CheckpointLoaderSimple",
      "_meta": {
        "title": "Load Checkpoint"
      }
    },
    "5": {
      "inputs": {
        "width": 1024,
        "height": 1024,
        "batch_size": 1
      },
      "class_type": "EmptyLatentImage",
      "_meta": {
        "title": "Empty Latent Image"
      }
    },
    "6": {
      "inputs": {
        "text": "upperbody shot,long hairs, happy, laugh, hugging a teddy bear, looking at viewers, dancing stand, cute, soft color, flowers in background, many flowers, among flowers, best quality, highres, delicate details,",
        "clip": ["4", 1]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "prompt"
      }
    },
    "7": {
      "inputs": {
        "text": "nsfw",
        "clip": ["4", 1]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "negativePrompt"
      }
    },
    "8": {
      "inputs": {
        "samples": ["3", 0],
        "vae": ["4", 2]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "9": {
      "inputs": {
        "filename_prefix": "AIPG_Image",
        "images": ["8", 0]
      },
      "class_type": "SaveImage",
      "_meta": {
        "title": "Save Image"
      }
    }
  }
}
