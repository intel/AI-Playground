{
  "type": "comfy",
  "name": "Acer VisionArt",
  "displayPriority": 150,
  "tags": [
    "Q4",
    "Fast"
  ],
  "backend": "comfyui",
  "category": "create-images",
  "requiredCustomNodes": [
    "city96/ComfyUI-GGUF@b3ec875a68d94b758914fd48d30571d953bb7a54",
    "AcerPartner/VisionArt@AI-Playground"
  ],
  "requiredPythonPackages": [],
  "requiredModels": [
    {
      "type": "unet",
      "model": "city96/FLUX.1-schnell-gguf/flux1-schnell-Q4_K_S.gguf"
    },
    {
      "type": "clip",
      "model": "city96/t5-v1_1-xxl-encoder-gguf/t5-v1_1-xxl-encoder-Q3_K_M.gguf"
    },
    {
      "type": "clip",
      "model": "comfyanonymous/flux_text_encoders/clip_l.safetensors"
    },
    {
      "type": "vae",
      "model": "Comfy-Org/Lumina_Image_2.0_Repackaged/split_files/vae/ae.safetensors"
    }
  ],
  "settings": [
    {
      "type": "string",
      "label": "Prompt",
      "displayed": false,
      "modifiable": true,
      "defaultValue": "",
      "settingName": "prompt"
    },
    {
      "type": "number",
      "label": "Seed",
      "displayed": false,
      "modifiable": true,
      "defaultValue": -1,
      "settingName": "seed"
    },
    {
      "type": "number",
      "label": "Inference Steps",
      "displayed": false,
      "modifiable": false,
      "defaultValue": 4,
      "settingName": "inferenceSteps"
    },
    {
      "type": "number",
      "label": "Width",
      "displayed": false,
      "modifiable": false,
      "defaultValue": 960,
      "settingName": "width"
    },
    {
      "type": "number",
      "label": "Height",
      "displayed": false,
      "modifiable": false,
      "defaultValue": 512,
      "settingName": "height"
    },
    {
      "type": "string",
      "label": "Resolution",
      "displayed": false,
      "modifiable": true,
      "defaultValue": "960x512",
      "settingName": "resolution"
    },
    {
      "type": "number",
      "label": "Batch Size",
      "displayed": false,
      "modifiable": false,
      "defaultValue": 1,
      "settingName": "batchSize"
    },
    {
      "type": "string",
      "label": "Negative Prompt",
      "displayed": false,
      "modifiable": false,
      "defaultValue": "nsfw",
      "settingName": "negativePrompt"
    },
    {
      "type": "boolean",
      "label": "Image Preview",
      "displayed": false,
      "modifiable": false,
      "defaultValue": true,
      "settingName": "imagePreview"
    },
    {
      "type": "boolean",
      "label": "Safety Check",
      "displayed": false,
      "modifiable": false,
      "defaultValue": true,
      "settingName": "safetyCheck"
    }
  ],
  "comfyUiApiWorkflow": {
    "169": {
      "inputs": {
        "noise": ["184", 0],
        "guider": ["178", 0],
        "sampler": ["185", 0],
        "sigmas": ["181", 0],
        "latent_image": ["180", 0]
      },
      "class_type": "SamplerCustomAdvanced",
      "_meta": {
        "title": "SamplerCustomAdvanced"
      }
    },
    "170": {
      "inputs": {
        "unet_name": "city96---FLUX.1-schnell-gguf\\flux1-schnell-Q4_K_S.gguf"
      },
      "class_type": "UnetLoaderGGUF",
      "_meta": {
        "title": "Unet Loader (GGUF)"
      }
    },
    "171": {
      "inputs": {
        "vae_name": "Comfy-Org---Lumina_Image_2.0_Repackaged\\split_files\\vae\\ae.safetensors"
      },
      "class_type": "VAELoader",
      "_meta": {
        "title": "Load VAE"
      }
    },
    "174": {
      "inputs": {
        "guidance": 1,
        "conditioning": ["177", 0]
      },
      "class_type": "FluxGuidance",
      "_meta": {
        "title": "FluxGuidance"
      }
    },
    "177": {
      "inputs": {
        "text": "A cool llama wearing a pair of sunglasses, holding a blue and purple neon sign that says \"Hello Intel\" in front, vibrant colors, blurry cyberpunk gaming background.",
        "clip": ["188", 0]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "prompt"
      }
    },
    "178": {
      "inputs": {
        "model": ["170", 0],
        "conditioning": ["174", 0]
      },
      "class_type": "BasicGuider",
      "_meta": {
        "title": "BasicGuider"
      }
    },
    "179": {
      "inputs": {
        "samples": ["169", 1],
        "vae": ["171", 0]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "180": {
      "inputs": {
        "width": 960,
        "height": 512,
        "batch_size": 1
      },
      "class_type": "EmptyLatentImage",
      "_meta": {
        "title": "Empty Latent Image"
      }
    },
    "181": {
      "inputs": {
        "scheduler": "normal",
        "steps": 1,
        "denoise": 1,
        "model": ["170", 0]
      },
      "class_type": "BasicScheduler",
      "_meta": {
        "title": "BasicScheduler"
      }
    },
    "184": {
      "inputs": {
        "noise_seed": 847414638968036
      },
      "class_type": "RandomNoise",
      "_meta": {
        "title": "RandomNoise"
      }
    },
    "185": {
      "inputs": {
        "sampler_name": "euler"
      },
      "class_type": "KSamplerSelect",
      "_meta": {
        "title": "KSamplerSelect"
      }
    },
    "188": {
      "inputs": {
        "clip_name1": "city96---t5-v1_1-xxl-encoder-gguf\\t5-v1_1-xxl-encoder-Q3_K_M.gguf",
        "clip_name2": "comfyanonymous---flux_text_encoders\\clip_l.safetensors",
        "type": "flux"
      },
      "class_type": "DualCLIPLoaderGGUF",
      "_meta": {
        "title": "DualCLIPLoader (GGUF)"
      }
    },
    "192": {
      "inputs": {
        "animation_mode": 2,
        "performance_mode": 0,
        "image": ["179", 0]
      },
      "class_type": "Acer",
      "_meta": {
        "title": "VisionArt Node"
      }
    },
    "193": {
      "inputs": {
        "filename_prefix": "AcerVisionArt",
        "images": ["192", 0]
      },
      "class_type": "AcerSaveImage",
      "_meta": {
        "title": "VisionArt SaveImage Node"
      }
    }
  }
}

