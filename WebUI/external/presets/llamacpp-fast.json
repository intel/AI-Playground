{
  "type": "chat",
  "name": "llamaCPP Fast",
  "description": "Utilizes Llama.cpp for lightweight and portable AI solutions. Ideal for low-resource environments.",
  "displayPriority": 90,
  "tags": ["Lightweight", "Portable", "Fast"],
  "backend": "llamaCPP",
  "systemPrompt": "You are a helpful AI assistant. Provide concise and accurate responses.",
  "contextSize": 4096,
  "maxNewTokens": 512,
  "requiredModels": []
}

