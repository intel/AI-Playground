{
  "type": "comfy",
  "name": "Inpaint SDXL",
  "displayPriority": 500,
  "tags": ["inpaint", "edit-images", "sdxl"],
  "backend": "comfyui",
  "category": "edit-images",
  "description": "Inpaint images using Stable Diffusion XL",
  "requiredCustomNodes": [],
  "requiredPythonPackages": [],
  "requiredModels": [
    {
      "type": "defaultCheckpoint",
      "model": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1/unet/diffusion_pytorch_model.safetensors"
    },
    {
      "type": "defaultCheckpoint",
      "model": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1/text_encoder/model.safetensors"
    },
    {
      "type": "defaultCheckpoint",
      "model": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1/text_encoder_2/model.safetensors"
    },
    {
      "type": "defaultCheckpoint",
      "model": "diffusers/stable-diffusion-xl-1.0-inpainting-0.1/vae/diffusion_pytorch_model.safetensors"
    }
  ],
  "settings": [
    {
      "type": "string",
      "label": "Prompt",
      "displayed": false,
      "modifiable": true,
      "defaultValue": "",
      "settingName": "prompt"
    },
    {
      "type": "number",
      "label": "Seed",
      "displayed": true,
      "modifiable": true,
      "defaultValue": -1,
      "settingName": "seed"
    },
    {
      "type": "number",
      "label": "Inference Steps",
      "displayed": true,
      "modifiable": true,
      "defaultValue": 20,
      "settingName": "inferenceSteps"
    },
    {
      "type": "number",
      "label": "Width",
      "displayed": false,
      "modifiable": false,
      "defaultValue": 1024,
      "settingName": "width"
    },
    {
      "type": "number",
      "label": "Height",
      "displayed": false,
      "modifiable": false,
      "defaultValue": 1024,
      "settingName": "height"
    },
    {
      "type": "number",
      "label": "Target Width",
      "nodeTitle": "width",
      "nodeInput": "value",
      "min": 64,
      "max": 2048,
      "step": 8,
      "defaultValue": 1024,
      "displayed": false,
      "modifiable": true
    },
    {
      "type": "number",
      "label": "Target Height",
      "nodeTitle": "height",
      "nodeInput": "value",
      "min": 64,
      "max": 2048,
      "step": 8,
      "defaultValue": 1024,
      "displayed": false,
      "modifiable": true
    },
    {
      "type": "string",
      "label": "Resolution",
      "displayed": true,
      "modifiable": true,
      "defaultValue": "1024x1024",
      "settingName": "resolution"
    },
    {
      "type": "number",
      "label": "Batch Size",
      "displayed": true,
      "modifiable": true,
      "defaultValue": 1,
      "settingName": "batchSize"
    },
    {
      "type": "string",
      "label": "Negative Prompt",
      "displayed": true,
      "modifiable": true,
      "defaultValue": "nsfw",
      "settingName": "negativePrompt"
    },
    {
      "type": "boolean",
      "label": "Image Preview",
      "displayed": true,
      "modifiable": true,
      "defaultValue": true,
      "settingName": "imagePreview"
    },
    {
      "type": "boolean",
      "label": "Safety Check",
      "displayed": false,
      "modifiable": false,
      "defaultValue": true,
      "settingName": "safetyCheck"
    },
    {
      "type": "image",
      "label": "Input Image",
      "nodeTitle": "Load Image",
      "nodeInput": "image",
      "defaultValue": "",
      "displayed": true,
      "modifiable": true
    },
    {
      "type": "inpaintMask",
      "label": "Inpaint Mask",
      "nodeTitle": "Load Image",
      "nodeInput": "image",
      "displayed": true,
      "modifiable": true
    },
    {
      "type": "number",
      "label": "Denoise",
      "nodeTitle": "KSampler",
      "nodeInput": "denoise",
      "min": 0.1,
      "max": 1.0,
      "step": 0.01,
      "defaultValue": 1.0,
      "displayed": false,
      "modifiable": false
    }
  ],
  "comfyUiApiWorkflow": {
    "1": {
      "inputs": {
        "image": "input.jpg",
        "upload": "image"
      },
      "class_type": "LoadImage",
      "_meta": {
        "title": "Load Image"
      }
    },
    "3": {
      "inputs": {
        "seed": 413053266758155,
        "steps": 20,
        "cfg": 7,
        "sampler_name": "dpmpp_2m",
        "scheduler": "normal",
        "denoise": 1.0,
        "model": [
          "11",
          0
        ],
        "positive": [
          "12",
          0
        ],
        "negative": [
          "12",
          1
        ],
        "latent_image": [
          "12",
          2
        ]
      },
      "class_type": "KSampler",
      "_meta": {
        "title": "KSampler"
      }
    },
    "4": {
      "inputs": {
        "vae_name": "diffusers---stable-diffusion-xl-1.0-inpainting-0.1\\vae\\diffusion_pytorch_model.safetensors"
      },
      "class_type": "VAELoader",
      "_meta": {
        "title": "Load VAE"
      }
    },
    "5": {
      "inputs": {
        "samples": [
          "3",
          0
        ],
        "vae": [
          "4",
          0
        ]
      },
      "class_type": "VAEDecode",
      "_meta": {
        "title": "VAE Decode"
      }
    },
    "6": {
      "inputs": {
        "text": "upperbody shot,long hairs, happy, laugh, hugging a teddy bear, looking at viewers, dancing stand, cute, soft color, flowers in background, many flowers, among flowers, best quality, highres, delicate details,",
        "clip": [
          "9",
          0
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "prompt"
      }
    },
    "7": {
      "inputs": {
        "text": "nsfw",
        "clip": [
          "9",
          0
        ]
      },
      "class_type": "CLIPTextEncode",
      "_meta": {
        "title": "negativePrompt"
      }
    },
    "11": {
      "inputs": {
        "model": [
          "10",
          0
        ]
      },
      "class_type": "DifferentialDiffusion",
      "_meta": {
        "title": "Differential Diffusion"
      }
    },
    "12": {
      "inputs": {
        "noise_mask": false,
        "positive": [
          "6",
          0
        ],
        "negative": [
          "7",
          0
        ],
        "vae": [
          "4",
          0
        ],
        "pixels": [
          "23",
          0
        ],
        "mask": [
          "14",
          0
        ]
      },
      "class_type": "InpaintModelConditioning",
      "_meta": {
        "title": "InpaintModelConditioning"
      }
    },
    "14": {
      "inputs": {
        "channel": "red",
        "image": [
          "25",
          0
        ]
      },
      "class_type": "ImageToMask",
      "_meta": {
        "title": "Convert Image to Mask"
      }
    },
    "15": {
      "inputs": {
        "mask": [
          "1",
          1
        ]
      },
      "class_type": "MaskToImage",
      "_meta": {
        "title": "Convert Mask to Image"
      }
    },
    "23": {
      "inputs": {
        "upscale_method": "bicubic",
        "width": [
          "27",
          0
        ],
        "height": [
          "28",
          0
        ],
        "crop": "center",
        "image": [
          "1",
          0
        ]
      },
      "class_type": "ImageScale",
      "_meta": {
        "title": "Upscale Image"
      }
    },
    "25": {
      "inputs": {
        "upscale_method": "bicubic",
        "width": [
          "27",
          0
        ],
        "height": [
          "28",
          0
        ],
        "crop": "center",
        "image": [
          "15",
          0
        ]
      },
      "class_type": "ImageScale",
      "_meta": {
        "title": "Upscale Image"
      }
    },
    "27": {
      "inputs": {
        "value": 1024
      },
      "class_type": "PrimitiveInt",
      "_meta": {
        "title": "width"
      }
    },
    "28": {
      "inputs": {
        "value": 1024
      },
      "class_type": "PrimitiveInt",
      "_meta": {
        "title": "height"
      }
    },
    "8": {
      "inputs": {
        "filename_prefix": "AIPG_Image",
        "images": [
          "5",
          0
        ]
      },
      "class_type": "SaveImage",
      "_meta": {
        "title": "Save Image"
      }
    },
    "9": {
      "inputs": {
        "clip_name1": "diffusers---stable-diffusion-xl-1.0-inpainting-0.1\\text_encoder\\model.safetensors",
        "clip_name2": "diffusers---stable-diffusion-xl-1.0-inpainting-0.1\\text_encoder_2\\model.safetensors",
        "type": "sdxl"
      },
      "class_type": "DualCLIPLoader",
      "_meta": {
        "title": "DualCLIPLoader"
      }
    },
    "10": {
      "inputs": {
        "unet_name": "diffusers---stable-diffusion-xl-1.0-inpainting-0.1\\unet\\diffusion_pytorch_model.safetensors",
        "weight_dtype": "default"
      },
      "class_type": "UNETLoader",
      "_meta": {
        "title": "Load Diffusion Model"
      }
    }
  }
}

